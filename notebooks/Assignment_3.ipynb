{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: RNN, Transformer and LLM-based Agent Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your environment activated int the terminal, run:\n",
    "```\n",
    "mamba env create -n cs5293-3 python=3.10\n",
    "pip install -r requirements.txt\n",
    "##Your VSCode may complain sometime you need to install ipykernel using the following commands. If not, then  just ignore this. \n",
    "#mamba install -n cs5293-3 ipykernel  --force-reinstall \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you have to submit two things:\n",
    "* (1) The whole folder with your code\n",
    "* (2) A report to summarize what your experienments in part 2 and part 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reading Assignment on Transformer Jupernotebook (20')\n",
    "\n",
    "There two excellent transformer juternote books at large, which covers a great amount details of transformer that we could cannot cover more in the class: [\"The Illustrated Transfomer\"](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar and [\"The Annotated Transformer\"](https://github.com/harvardnlp/annotated-transformer/) by harvardnlp lab.\n",
    "\n",
    "Some one combined this two and create a single jupternotebook [here](https://github.com/vinsis/math-and-ml-notes/blob/master/notebooks/Transformer%20-%20Illustration%20and%20code.ipynb). You need to do the following:\n",
    "\n",
    "1. Adjust your own requirements.txt (if necessary to your environment) to make that notebook all runnable\n",
    "2. Understand the details of the key components of transformer, run through the code, and take any notes you want to take on this notebook. \n",
    "3. This note book could be printed out for the final exam, but if you don't understand them before the exam. It will be hard. \n",
    "\n",
    "What to turn in: your own annotations on the above notebook that you will bring with you to the final exam. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Programming Assignment (Total: 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Assignment 2, you have worked on a 5-way deep average network on sentiment dataset (SST-5), which has 5 labels: very positive, positive, neutral, negative, very negative.  However, the performance is realtive low. \n",
    "\n",
    "In this part, based on the same SST-5 dataset, you have two tasks:\n",
    "* Section 2.1. Using builtin pytorch 1-layer LSTM with the same given word embedding to improve the performance. (30')\n",
    "* Sextion 2.2 Using the library of Huggingface Transformers to improve your model with BERT Finetuning.(30' + 10')\n",
    "\n",
    "Important Hints:\n",
    "\n",
    "1. You will find a ton of existing code for this two tasks, it is ok to refer or reuse some of thsoe code. \n",
    "2. But some of those code are too old. You SHOULD use the lastest stable pytorch(2.6.0) and huggingface tranformers(>4.50.0) for this. \n",
    "3. To run a batch job on OSCER, you need to reassemble the code from the notebook into regular source code to submit a slurm job.\n",
    "\n",
    "What to turn in: You need to turn in the code and a pdf report to show the performance of your two new models on SST-5 dataset.\n",
    "Performance Metrics: \n",
    "* Classification Report in Sklearn (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "* Confusion Matrix (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1 Pytorch LSTM (30)\n",
    "\n",
    "Your goal: Add a new pytorch model(nn.module) using the 1-layer LSTM module for your SST-5 sentiment classifier in assignment 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: There are tons of tutorial of using pytorch LSTM, even for this SST-5 dataset... \n",
    "1. https://github.com/doslim/Sentiment-Analysis-SST5/blob/8f041635a3b959a405e2105bc9037b6af77aa7ba/semtiment%20analysis/codes/model.py#L45 This one use both lstm and attention. You just need to play with lstm with hyper parameters (such as hidden layer size, learning rate, weight decay, etc.) \n",
    "2. https://colab.research.google.com/gist/SauravMaheshkar/168f0817f0cd29dd4048868fb0dd4401/lstms-in-pytorch.ipynb#scrollTo=BKAA2rR0-B-3  This also introduce the code how to use wandb to track your experiments, which will be very useful for your project.\n",
    "\n",
    "What to Report:\n",
    "\n",
    "* Your LSTM hyperparameters (https://medium.com/geekculture/10-hyperparameters-to-keep-an-eye-on-for-your-lstm-model-and-other-tips-f0ff5b63fcd4)\n",
    "\n",
    "* Performance Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2 Huggingface Transformer, Various LMs (30)\n",
    "\n",
    "Your goal: use the huggingface transformers library to rebuilt your sentiment classifier\n",
    "There are a lot of old version codes of using BERT for SST-5, DON\"T use them but read them will help you understand. \n",
    "They are obsolete but they have more details. \n",
    "Such as this one. https://github.com/munikarmanish/bert-sentiment/blob/master/bert_sentiment/train.py \n",
    "\n",
    "The most recent version of huggingface is easy to use but hide too many details. \n",
    "I hope to make your life easier, please use the eaiser pytorch version of this following tutoral for SST-5.\n",
    " https://huggingface.co/docs/transformers/en/tasks/sequence_classification \n",
    "\n",
    "When you run this jupternobook, you will get prompted to two accounts:\n",
    "\n",
    "1. Create a huggingface account and create a [access token](https://huggingface.co/docs/hub/en/security-tokens) to login in this note book.\n",
    "2. Create a wandb account to keep the log into the wandb, which has been automaitically integrated into hugginface trainer to track your experiments.  See the details here. https://docs.wandb.ai/guides/integrations/huggingface/ \n",
    "\n",
    "\n",
    "The above tutorial will take you about 40 minutes to run on an old [Nvidia Tesla T4 GPU](https://colab.research.google.com/github/d2l-ai/d2l-tvm-colab/blob/master/chapter_gpu_schedules/arch.ipynb) with the free version of Colab, and sometimes it is slow. So try the Oscer first, then paid Colab GPU.\n",
    "\n",
    "Your Task:\n",
    "* See if you could replace the dataset with SST-5, and the model with \"bert-base-cased\" and get familiar with this new framework for your sentiment classifier, report the final performance.\n",
    "\n",
    "(HINT: you almost only need to change the parameters in AutoTokenizer, and AutoModelXX, the learning rate for finetuning is often small (around 10^-3 to 10^-5), the epoch is also around 3 to 10)\n",
    "\n",
    "What to Report: \n",
    "\n",
    "* Your BERT related training hyperparameters.\n",
    "* Performance Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: LLM-based Exam Agent For NLP (20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agentic AI is a popular word nowadays. People in CS or Non-CS uses LLM models to build all kinds of Agents with no-code or low code fashion. Please read a Nvidia's introduction about Agentic AI. https://blogs.nvidia.com/blog/what-is-agentic-ai/\n",
    "\n",
    "In this assignment, we focus on the ngram question we used in version A of our mid-term(), let us build a simple agent to solve this via LangChain.\n",
    "\n",
    "## Requirements:\n",
    "* API version of Open AI: The agent requires you to obtain your OPENAI_API_KEY by binding your bank account to OpenAI. It is Pay-as-you-go serveice, it will be a few dollars for this assignment.\n",
    "* ChatGPT-free version: You need to test ChatGPT's capability for the questions. Students can claim 2 months of ChatGPT Plus for free. Get access to premium features when you verify youâ€™re a student in the US or Canada. https://chatgpt.com/students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1. The standard way you use ChatGPT Everyday! (chatgpt.com)\n",
    "\n",
    "By the time of this assignment, the default model of ChatGPT is GPT-4o (GPT-4-omini). \n",
    "The model is capable of performing a wide range of tasks and using tools. Hence, you can ask it answer the above question 3 and 4. You will find out the default ChatGPT(GPT-4o) works great!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.2. API and PlayGround: The Researcher's Way Using ChatGPT\n",
    "\n",
    "Now let's  test some previous LLMs from OpenAI, \n",
    "https://platform.openai.com/playground/prompts?models=gpt-4o\n",
    "When we test the GPT-3.5-turbo(That is the earlier version of ChatGPT). We found that the previous model could not finish the whole solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.3. Let's Build Our Own NGram Agent with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [Exam_Agent_For_NLP.ipynb](Exam_Agent_For_NLP.ipynb) in the notebooks folder, build your own agent.\n",
    "Step 1. Test through the code, see only using more atomic tools such as \"extract_text\",\"count_occurrences\", \"divid\", \"multiply\", see if \"GPT-3.5-turbo\" will use help.\n",
    "Step 2. Could you reuse the assignment 1 to fill in the unimplemented bigram-related functions, see if your agent could use the new advanced tools. \n",
    "\n",
    "[Hint: The \"GPT-3.5-turbo\" is not perfect and may not stable, so please just report you find]\n",
    "\n",
    "What to turn in: \n",
    "\n",
    "1. The notebook itself\n",
    "2. Writing your finding into the single seperate report you need to turn in. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5293-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
